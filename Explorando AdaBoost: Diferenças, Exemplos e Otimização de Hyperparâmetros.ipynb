{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d769fd",
   "metadata": {},
   "source": [
    "<font size=\"4\"> MÓDULO 24 - TAREFA 1 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3806d9",
   "metadata": {},
   "source": [
    "<font size=\"3\">**1. Cite 5 diferenças entre o Random Forest e o AdaBoost.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867d95f",
   "metadata": {},
   "source": [
    "<font size=\"3\"> <u>Tipo de Algoritmo:</u> No <b>Random Forest</b> são criadas várias árvores de decisão independentes durante o treinamento e em seguida combinados os seus resultados, no <b>AdaBoost</b> também são criadas várias árvores de decisão, mas neste método o foco está em melhorar sequencialmente o modelo corrigindo suas imperfeições e melhorando-o.</font>\n",
    "\n",
    "<font size=\"3\"> <u>Peso dos Exemplos:</u> No <b>Random Forest</b> as árvores são treinadas de forma independente, sem considerar qualquer desempenho das demais, tendo o mesmo peso na decisão final, no <b>AdaBoost</b> os exemplos possuem pesos diferentes, sendo mais priorizados as árvores que tiveram um pior desempenho, sendo possível assim a melhora destas falhas nas árvores subsequentes.</font>\n",
    "\n",
    "<font size=\"3\"> <u>Combinação de Previsões:</u> No <b>Random Forest</b> As previsões são combinadas através de votação ou média a depender de qual problema estamos lidando, no <b>AdaBoost</b> as previsões também são combinadas através de votação, mas priorizando as árvores que tiveram melhor desempenho anteriormente.</font>\n",
    "\n",
    "<font size=\"3\"> <u>Overfitting:</u> No <b>Random Forest</b> há uma vantagem neste quesito, pois as árvores são limitadas em tamanho e sua combinação reduz o impacto de uma única árvore extremamente complexa, no <b>AdaBoost</b> o overfitting pode ter mais chances de ocorrer, pois este método tenta corrigir ao máximo os erros das árvores anteriores, podendo se ajustar demais aos dados.</font>\n",
    "\n",
    "<font size=\"3\"> <u>Número de Hiperparâmetros:</u> No <b>Random Forest</b> há diversos hiperparâmetros a serem ajustados, como número de árvores, profundidade máxima entre outros, no <b>AdaBoost</b> não há tantos hiperparâmetros que podem ser ajustados como no método anterior.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572b144",
   "metadata": {},
   "source": [
    "<font size=\"3\">**2. Acesse o link Scikit-learn – adaboost, leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost..**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e223018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0aea10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#  ACRESCENTEI MAIS UM EXEMPLO UTILIZANDO O BANCO DE DADOS \"BREAST CANCER WISCONSIN\" QUE É FREQUENTEMENTE UTILIZADO\n",
    "#  PARA FINS DE APRENDIZADO E PRÁTICA EM PROBLEMAS DE CLASSIFICAÇÃO BINÁRIA, POIS É UM CONJUNTO DE DADOS QUE DETECTA \n",
    "#  CÂNCER DE MAMA MALIGNO OU BENIGNO COM BASE EM DIVERSAS CARACTERÍSTICAS.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregando o conjunto de dados Breast Cancer Wisconsin\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criando um classificador AdaBoost\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinando o classificador\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculando a precisão das previsões\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b5e08",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3. Cite 5 Hyperparametros importantes no AdaBoost.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d4952",
   "metadata": {},
   "source": [
    "<font size=\"3\"> 1. <u>n_estimators:</u> Número de estimadores fracos que o Adaboost irá treinar.</font>\n",
    "\n",
    "<font size=\"3\"> 2. <u>learning_rate:</u> Controla a contribuição de cada estimador fraco para o modelo final.</font>\n",
    "\n",
    "<font size=\"3\"> 3. <u>base_estimator:</u> Permite a escolha do tipo de estimador fraco que será utilizado.</font>\n",
    "\n",
    "<font size=\"3\"> 4. <u>algorithm:</u> Controla como os pesos das instâncias são atualizados a cada iteração do AdaBoost.</font>\n",
    "\n",
    "<font size=\"3\"> 5. <u>random_state:</u> Controla a semente aleatória utilizada para inicialização dos componentes aleatórios no algoritmo.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49bbbc",
   "metadata": {},
   "source": [
    "<font size=\"3\">**4. (Opcional) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5796ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Hiperparâmetros: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Melhor Pontuação: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Carregar o conjunto de dados Iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Definir os valores para os hiperparâmetros que deseja testar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Criar o classificador AdaBoost\n",
    "base_clf = AdaBoostClassifier()\n",
    "\n",
    "# Criar um objeto GridSearchCV\n",
    "grid_search = GridSearchCV(base_clf, param_grid, cv=5)\n",
    "\n",
    "# Realizar a busca dos melhores hiperparâmetros\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir os melhores hiperparâmetros e a melhor pontuação\n",
    "print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor Pontuação:\", grid_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
